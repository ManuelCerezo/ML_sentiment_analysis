{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["22/05/02 19:40:59 WARN Utils: Your hostname, herex resolves to a loopback address: 127.0.1.1; using 10.245.4.22 instead (on interface wlp58s0)\n","22/05/02 19:40:59 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n","WARNING: An illegal reflective access operation has occurred\n","WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/herex/.local/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n","WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n","WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","WARNING: All illegal access operations will be denied in a future release\n","Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n","Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","22/05/02 19:41:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","22/05/02 19:41:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"]}],"source":["import findspark\n","findspark.init()\n","import pyspark\n","sc = pyspark.SparkContext(appName=\"LOGISTICREG\")\n","from pyspark.sql.session import SparkSession\n","spark = SparkSession(sc)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["#read the dataset\n","df=spark.read.csv('data.csv',inferSchema=True,header=True)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- id: integer (nullable = true)\n"," |-- date: string (nullable = true)\n"," |-- news: string (nullable = true)\n"," |-- final_manual_labelling: integer (nullable = true)\n","\n"]}],"source":["df.printSchema()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+---------+--------------------+----------------------+\n","| id|     date|                news|final_manual_labelling|\n","+---+---------+--------------------+----------------------+\n","|  0|1/25/2022|Ripple announces ...|                     1|\n","|  1|1/25/2022|IMF directors urg...|                    -1|\n","|  2|1/25/2022|Dragonfly Capital...|                     1|\n","|  3|1/25/2022|Rick and Morty co...|                     0|\n","|  4|1/25/2022|How fintech SPACs...|                     0|\n","+---+---------+--------------------+----------------------+\n","only showing top 5 rows\n","\n"]}],"source":["df.show(5)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+---------+---------------------------------------------------------------------------------------------------+\n","|id |date     |tokens                                                                                             |\n","+---+---------+---------------------------------------------------------------------------------------------------+\n","|0  |1/25/2022|[ripple, announces, stock, buyback,, nabs, $15, billion, valuation]                                |\n","|1  |1/25/2022|[imf, directors, urge, el, salvador, to, remove, bitcoin, as, legal, tender]                       |\n","|2  |1/25/2022|[dragonfly, capital, is, raising, $500, million, for, new, fund]                                   |\n","|3  |1/25/2022|[rick, and, morty, co-creator, collaborates, with, paradigm, on, nft, research, project]           |\n","|4  |1/25/2022|[how, fintech, spacs, lost, their, shine]                                                          |\n","|5  |1/25/2022|[multichain, vulnerability, put, a, billion, dollars, at, risk,, says, firm, that, found, the, bug]|\n","|6  |1/25/2022|[youtube, wants, to, help, content, creators, capitalize, on, nfts]                                |\n","|7  |1/25/2022|[opensea, is, reimbursing, users, who, sold, nfts, below, market, value, due, to, ui, issue]       |\n","|8  |1/25/2022|[gooddollar, launches, key, protocol, upgrade, to, expand, crypto-backed, ubi, ecosystem]          |\n","|9  |1/25/2022|[bcb, group, raises, a, $60, million, series, a, round, co-led, by, foundation, capital]           |\n","+---+---------+---------------------------------------------------------------------------------------------------+\n","only showing top 10 rows\n","\n"]}],"source":["from pyspark.ml.feature import Tokenizer\n","tokenization=Tokenizer(inputCol='news',outputCol='tokens')\n","tokenized_df=tokenization.transform(df)\n","tokenized_df.select(['id','date','tokens']).show(10,False)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+---------+-------------------------------------------------------------------------------------+\n","|id |date     |refined_tokens                                                                       |\n","+---+---------+-------------------------------------------------------------------------------------+\n","|0  |1/25/2022|[ripple, announces, stock, buyback,, nabs, $15, billion, valuation]                  |\n","|1  |1/25/2022|[imf, directors, urge, el, salvador, remove, bitcoin, legal, tender]                 |\n","|2  |1/25/2022|[dragonfly, capital, raising, $500, million, new, fund]                              |\n","|3  |1/25/2022|[rick, morty, co-creator, collaborates, paradigm, nft, research, project]            |\n","|4  |1/25/2022|[fintech, spacs, lost, shine]                                                        |\n","|5  |1/25/2022|[multichain, vulnerability, put, billion, dollars, risk,, says, firm, found, bug]    |\n","|6  |1/25/2022|[youtube, wants, help, content, creators, capitalize, nfts]                          |\n","|7  |1/25/2022|[opensea, reimbursing, users, sold, nfts, market, value, due, ui, issue]             |\n","|8  |1/25/2022|[gooddollar, launches, key, protocol, upgrade, expand, crypto-backed, ubi, ecosystem]|\n","|9  |1/25/2022|[bcb, group, raises, $60, million, series, round, co-led, foundation, capital]       |\n","+---+---------+-------------------------------------------------------------------------------------+\n","only showing top 10 rows\n","\n"]}],"source":["from pyspark.ml.feature import StopWordsRemover\n","stopword_removal=StopWordsRemover(inputCol='tokens',outputCol='refined_tokens')\n","refined_df=stopword_removal.transform(tokenized_df)\n","refined_df.select(['id','date','refined_tokens']).show(10,False)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+-------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------+\n","|id |refined_tokens                                                           |tf_features                                                                                                |\n","+---+-------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------+\n","|0  |[ripple, announces, stock, buyback,, nabs, $15, billion, valuation]      |(262144,[18697,51983,64360,74682,97558,109858,110856,198843],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])            |\n","|1  |[imf, directors, urge, el, salvador, remove, bitcoin, legal, tender]     |(262144,[26144,41351,54828,65374,124004,132778,189902,214592,248887],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n","|2  |[dragonfly, capital, raising, $500, million, new, fund]                  |(262144,[55307,82062,89833,130361,155266,221709,258654],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])                     |\n","|3  |[rick, morty, co-creator, collaborates, paradigm, nft, research, project]|(262144,[50886,53101,68194,113715,143720,202501,205209,225729],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])          |\n","+---+-------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------+\n","only showing top 4 rows\n","\n"]}],"source":["from pyspark.ml.feature import HashingTF,IDF\n","hashing_vec=HashingTF(inputCol='refined_tokens',outputCol='tf_features')\n","hashing_df=hashing_vec.transform(refined_df)\n","hashing_df.select(['id','refined_tokens','tf_features']).show(4,False)\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["tf_idf_vec=IDF(inputCol='tf_features',outputCol='tf_idf_features')"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["22/05/02 19:41:12 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n"]},{"name":"stdout","output_type":"stream","text":["+---+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|id |tf_idf_features                                                                                                                                                                                                                          |\n","+---+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|0  |(262144,[18697,51983,64360,74682,97558,109858,110856,198843],[4.398555936625092,5.497168225293202,6.285625585657472,4.717009667743627,3.7679291130464807,3.212932270967353,5.592478405097527,7.201916317531627])                         |\n","|1  |(262144,[26144,41351,54828,65374,124004,132778,189902,214592,248887],[7.201916317531627,5.497168225293202,7.201916317531627,6.285625585657472,4.676187673223372,1.723362900680657,5.122474775851791,5.815621956411737,6.508769136971682])|\n","|2  |(262144,[55307,82062,89833,130361,155266,221709,258654],[1.7088548741910787,5.815621956411737,2.5432053646155057,5.697838920755353,6.508769136971682,4.088401008321252,3.3952538277613074])                                              |\n","|3  |(262144,[50886,53101,68194,113715,143720,202501,205209,225729],[4.257477338365186,7.201916317531627,5.592478405097527,7.201916317531627,5.497168225293202,7.201916317531627,2.637568126063791,7.201916317531627])                        |\n","+---+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","only showing top 4 rows\n","\n"]}],"source":["tf_idf_df=tf_idf_vec.fit(hashing_df).transform(hashing_df)\n","tf_idf_df.select(['id','tf_idf_features']).show(4,False)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------------------+-----+\n","|final_manual_labelling|count|\n","+----------------------+-----+\n","|                    -1|  258|\n","|                     1| 1184|\n","|                     0| 1241|\n","+----------------------+-----+\n","\n"]}],"source":["text_df=tf_idf_df.filter(((tf_idf_df.final_manual_labelling =='1') | (tf_idf_df.final_manual_labelling =='-1')| (tf_idf_df.final_manual_labelling =='0')))\n","text_df.groupBy('final_manual_labelling').count().show()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["22/05/02 19:41:14 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n","[Stage 11:>                                                         (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+----+----------+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+-----------+\n","|  id|      date|                news|final_manual_labelling|              tokens|      refined_tokens|         tf_features|     tf_idf_features|token_count|\n","+----+----------+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+-----------+\n","| 531|11/23/2021|Canadian investme...|                     0|[canadian, invest...|[canadian, invest...|(262144,[22371,46...|(262144,[22371,46...|         11|\n","|  51| 1/20/2022|Crypto staking fi...|                     1|[crypto, staking,...|[crypto, staking,...|(262144,[7132,553...|(262144,[7132,553...|         12|\n","|1037| 9/20/2021|Homeland Security...|                     1|[homeland, securi...|[homeland, securi...|(262144,[22732,31...|(262144,[22732,31...|          8|\n","| 980| 9/27/2021|Immutable X raise...|                     0|[immutable, x, ra...|[immutable, x, ra...|(262144,[7155,553...|(262144,[7155,553...|          9|\n","| 740|10/27/2021|El Salvador annou...|                     1|[el, salvador, an...|[el, salvador, an...|(262144,[6034,181...|(262144,[6034,181...|         10|\n","|  85| 1/17/2022|Binance partners ...|                     1|[binance, partner...|[binance, partner...|(262144,[53217,10...|(262144,[53217,10...|          8|\n","|1022| 9/21/2021|US Treasury sanct...|                    -1|[us, treasury, sa...|[us, treasury, sa...|(262144,[55307,57...|(262144,[55307,57...|         10|\n","|1462| 7/16/2021|China publishes f...|                     1|[china, publishes...|[china, publishes...|(262144,[6249,174...|(262144,[6249,174...|          9|\n","|2307|  3/5/2021|Demand for bitcoi...|                     0|[demand, for, bit...|[demand, bitcoin,...|(262144,[9030,210...|(262144,[9030,210...|         12|\n","| 373|12/10/2021|Peter Thiel Backe...|                     0|[peter, thiel, ba...|[peter, thiel, ba...|(262144,[27002,40...|(262144,[27002,40...|         10|\n","+----+----------+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+-----------+\n","only showing top 10 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["from pyspark.sql.functions import udf\n","from pyspark.sql.types import IntegerType\n","from pyspark.sql.functions import *\n","\n","len_udf = udf(lambda s: len(s), IntegerType())\n","\n","refined_text_df = tf_idf_df.withColumn(\"token_count\", len_udf(col('refined_tokens')))\n","refined_text_df.orderBy(rand()).show(10)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["refined_text_df = refined_text_df.withColumn(\"Label\", refined_text_df.final_manual_labelling.cast('float')).drop('final_manual_labelling')"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["['id',\n"," 'date',\n"," 'news',\n"," 'tokens',\n"," 'refined_tokens',\n"," 'tf_features',\n"," 'tf_idf_features',\n"," 'token_count',\n"," 'Label']"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["refined_text_df.columns"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["22/05/02 19:41:17 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n"]},{"name":"stdout","output_type":"stream","text":["+---+---------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+-----+-------------+-------------+\n","| id|     date|                news|              tokens|      refined_tokens|         tf_features|     tf_idf_features|token_count|Label|LabelNegative|LabelPositive|\n","+---+---------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+-----+-------------+-------------+\n","|  0|1/25/2022|Ripple announces ...|[ripple, announce...|[ripple, announce...|(262144,[18697,51...|(262144,[18697,51...|          8|  1.0|          0.0|          1.0|\n","|  1|1/25/2022|IMF directors urg...|[imf, directors, ...|[imf, directors, ...|(262144,[26144,41...|(262144,[26144,41...|          9| -1.0|          1.0|          0.0|\n","|  2|1/25/2022|Dragonfly Capital...|[dragonfly, capit...|[dragonfly, capit...|(262144,[55307,82...|(262144,[55307,82...|          7|  1.0|          0.0|          1.0|\n","|  3|1/25/2022|Rick and Morty co...|[rick, and, morty...|[rick, morty, co-...|(262144,[50886,53...|(262144,[50886,53...|          8|  0.0|          0.0|          0.0|\n","|  4|1/25/2022|How fintech SPACs...|[how, fintech, sp...|[fintech, spacs, ...|(262144,[19153,36...|(262144,[19153,36...|          4|  0.0|          0.0|          0.0|\n","+---+---------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+-----+-------------+-------------+\n","only showing top 5 rows\n","\n"]}],"source":["#Tenemos que crear dos modelos ,valor positivo y el resto, y valor negativo y el resto (1,0), y comparar los dos modelos (-1,0)\n","from pyspark.sql.functions import udf\n","from pyspark.sql.types import *\n","\n","funct_negative_label = udf(lambda x: 1.00 if x == -1 else 0.00, FloatType())\n","func_positive_label = udf(lambda x: 1.00 if x == 1 else 0.00, FloatType())\n","\n","refined_text_df = refined_text_df.withColumn(\"LabelNegative\",funct_negative_label('Label'))\n","refined_text_df = refined_text_df.withColumn(\"LabelPositive\",func_positive_label('Label'))\n","\n","refined_text_df.show(5)\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# Veamos si las dos matrices generadas cumplen las caracteristicas que queriamos"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["#Ponemos en el filtro todos los casos 1,0,-1 para ver que las negativas no tenga ningun 1, y las positivas ningun -1\n","text_df_positivo=refined_text_df.filter(((refined_text_df.LabelPositive =='1') | (refined_text_df.LabelPositive =='-1')| (refined_text_df.LabelPositive =='0')))\n","text_df_negativo=refined_text_df.filter(((refined_text_df.LabelNegative =='1') | (refined_text_df.LabelNegative =='-1')| (refined_text_df.LabelNegative =='0')))\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------------+-----+\n","|LabelNegative|count|\n","+-------------+-----+\n","|          1.0|  258|\n","|          0.0| 2425|\n","+-------------+-----+\n","\n"]}],"source":["text_df_negativo.groupBy('LabelNegative').count().show()"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------------+-----+\n","|LabelPositive|count|\n","+-------------+-----+\n","|          1.0| 1184|\n","|          0.0| 1499|\n","+-------------+-----+\n","\n"]}],"source":["text_df_positivo.groupBy('LabelPositive').count().show()"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["from pyspark.ml.feature import VectorAssembler\n","\n","df_assembler = VectorAssembler(inputCols=['tf_idf_features','token_count'],outputCol='features_vec')\n","model_text_df = df_assembler.transform(refined_text_df)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["22/05/02 19:41:20 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n"]},{"name":"stdout","output_type":"stream","text":["+---+---------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+-----+-------------+-------------+--------------------+\n","| id|     date|                news|              tokens|      refined_tokens|         tf_features|     tf_idf_features|token_count|Label|LabelNegative|LabelPositive|        features_vec|\n","+---+---------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+-----+-------------+-------------+--------------------+\n","|  0|1/25/2022|Ripple announces ...|[ripple, announce...|[ripple, announce...|(262144,[18697,51...|(262144,[18697,51...|          8|  1.0|          0.0|          1.0|(262145,[18697,51...|\n","|  1|1/25/2022|IMF directors urg...|[imf, directors, ...|[imf, directors, ...|(262144,[26144,41...|(262144,[26144,41...|          9| -1.0|          1.0|          0.0|(262145,[26144,41...|\n","|  2|1/25/2022|Dragonfly Capital...|[dragonfly, capit...|[dragonfly, capit...|(262144,[55307,82...|(262144,[55307,82...|          7|  1.0|          0.0|          1.0|(262145,[55307,82...|\n","|  3|1/25/2022|Rick and Morty co...|[rick, and, morty...|[rick, morty, co-...|(262144,[50886,53...|(262144,[50886,53...|          8|  0.0|          0.0|          0.0|(262145,[50886,53...|\n","|  4|1/25/2022|How fintech SPACs...|[how, fintech, sp...|[fintech, spacs, ...|(262144,[19153,36...|(262144,[19153,36...|          4|  0.0|          0.0|          0.0|(262145,[19153,36...|\n","+---+---------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+-----+-------------+-------------+--------------------+\n","only showing top 5 rows\n","\n"]}],"source":["model_text_df.show(5)\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["from pyspark.ml.classification import LogisticRegression\n","#split the data \n","training_df_negative,test_df_negative=model_text_df.randomSplit([0.75,0.25])\n","#split the data \n","training_df_positive,test_df_positive=model_text_df.randomSplit([0.75,0.25])"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["22/05/02 19:41:24 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:26 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:27 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n","22/05/02 19:41:27 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n","22/05/02 19:41:28 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:30 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:31 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:32 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:33 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:34 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:36 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:36 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:38 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:39 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:40 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:41 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:42 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:43 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:45 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:46 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:47 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:48 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:49 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:50 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:52 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:53 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:54 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:55 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:56 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:57 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:58 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:41:59 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:00 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:01 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:03 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:07 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:08 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:09 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:10 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:11 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:13 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:14 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:15 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:16 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:17 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:18 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:19 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:20 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:21 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:22 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:23 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:24 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:25 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:26 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:28 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:29 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:29 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:31 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:32 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:33 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:34 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:35 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:36 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:38 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:39 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:40 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:41 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:42 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","22/05/02 19:42:43 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","                                                                                \r"]}],"source":["log_reg_positive = LogisticRegression(featuresCol='features_vec',labelCol='LabelPositive').fit(training_df_positive)\n","log_reg_negative = LogisticRegression(featuresCol='features_vec',labelCol='LabelNegative').fit(training_df_negative)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["log_reg_negative.write().save(\"./model_neg\")\n","log_reg_positive.write().save(\"./model_pos\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# model_neg = LogisticRegression.load(\"model_neg\")\n","# model_pos = LogisticRegression.load(\"model_pos\")"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/herex/.local/lib/python3.8/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n","  warnings.warn(\n"]}],"source":["results_positive = log_reg_positive.evaluate(test_df_positive).predictions\n","results_negative = log_reg_negative.evaluate(test_df_negative).predictions"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["22/05/02 19:43:16 WARN DAGScheduler: Broadcasting large task binary with size 20.6 MiB\n","[Stage 87:>                                                         (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+---+---------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+-----+-------------+-------------+--------------------+--------------------+--------------------+----------+\n","| id|     date|                news|              tokens|      refined_tokens|         tf_features|     tf_idf_features|token_count|Label|LabelNegative|LabelPositive|        features_vec|       rawPrediction|         probability|prediction|\n","+---+---------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+-----+-------------+-------------+--------------------+--------------------+--------------------+----------+\n","| 11|1/25/2022|Twitter is growin...|[twitter, is, gro...|[twitter, growing...|(262144,[1512,480...|(262144,[1512,480...|          5|  1.0|          0.0|          1.0|(262145,[1512,480...|[15.7481994773413...|[0.99999985524159...|       0.0|\n","| 13|1/24/2022|Walmart director ...|[walmart, directo...|[walmart, directo...|(262144,[13981,10...|(262144,[13981,10...|          8|  1.0|          0.0|          1.0|(262145,[13981,10...|[-18.089766626933...|[1.39224019804928...|       1.0|\n","| 14|1/24/2022|Congressman McHen...|[congressman, mch...|[congressman, mch...|(262144,[22900,35...|(262144,[22900,35...|          9| -1.0|          1.0|          0.0|(262145,[22900,35...|[16.1819493415902...|[0.99999990618578...|       0.0|\n","| 24|1/23/2022|Traders are compl...|[traders, are, co...|[traders, complai...|(262144,[4075,383...|(262144,[4075,383...|         10| -1.0|          1.0|          0.0|(262145,[4075,383...|[-17.659190714291...|[2.14146464449748...|       1.0|\n","| 25|1/22/2022|Crypto stock plun...|[crypto, stock, p...|[crypto, stock, p...|(262144,[8145,978...|(262144,[8145,978...|          8|  0.0|          0.0|          0.0|(262145,[8145,978...|[-6.9262612779883...|[9.80701466058626...|       1.0|\n","+---+---------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+-----+-------------+-------------+--------------------+--------------------+--------------------+----------+\n","only showing top 5 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["results_positive.show(5)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["22/05/02 19:43:51 WARN DAGScheduler: Broadcasting large task binary with size 20.6 MiB\n","22/05/02 19:43:53 WARN DAGScheduler: Broadcasting large task binary with size 20.6 MiB\n","22/05/02 19:43:54 WARN DAGScheduler: Broadcasting large task binary with size 20.6 MiB\n","22/05/02 19:43:55 WARN DAGScheduler: Broadcasting large task binary with size 20.6 MiB\n","                                                                                \r"]}],"source":["#confusion matrix positive model\n","true_postives = results_positive[(results_positive.Label == 1) & (results_positive.prediction == 1)].count()\n","true_negatives = results_positive[(results_positive.Label == 0) & (results_positive.prediction == 0)].count()\n","false_positives = results_positive[(results_positive.Label == 0) & (results_positive.prediction == 1)].count()\n","false_negatives = results_positive[(results_positive.Label == 1) & (results_positive.prediction == 0)].count()"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.6589403973509934\n"]}],"source":["recall = float(true_postives)/(true_postives + false_negatives)\n","print(recall)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.6958041958041958\n"]}],"source":["precision = float(true_postives) / (true_postives + false_positives)\n","print(precision)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["22/05/02 19:44:14 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","[Stage 100:>                                                        (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["0.6153846153846154\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["accuracy=float((true_postives+true_negatives) /(results_positive.count()))\n","print(accuracy)"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["22/05/02 19:44:19 WARN DAGScheduler: Broadcasting large task binary with size 20.6 MiB\n","22/05/02 19:44:20 WARN DAGScheduler: Broadcasting large task binary with size 20.6 MiB\n","22/05/02 19:44:22 WARN DAGScheduler: Broadcasting large task binary with size 20.6 MiB\n","22/05/02 19:44:24 WARN DAGScheduler: Broadcasting large task binary with size 20.6 MiB\n","                                                                                \r"]}],"source":["#confusion matrix negative model\n","true_postives = results_negative[(results_negative.Label == 1) & (results_negative.prediction == 1)].count()\n","true_negatives = results_negative[(results_negative.Label == 0) & (results_negative.prediction == 0)].count()\n","false_positives = results_negative[(results_negative.Label == 0) & (results_negative.prediction == 1)].count()\n","false_negatives = results_negative[(results_negative.Label == 1) & (results_negative.prediction == 0)].count()"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.027777777777777776\n"]}],"source":["recall = float(true_postives)/(true_postives + false_negatives)\n","print(recall)"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.3333333333333333\n"]}],"source":["precision = float(true_postives) / (true_postives + false_positives)\n","print(precision)"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["22/05/02 19:44:25 WARN DAGScheduler: Broadcasting large task binary with size 20.5 MiB\n","[Stage 115:>                                                        (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["0.44461538461538463\n"]},{"name":"stderr","output_type":"stream","text":["22/05/02 22:37:10 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 2897258 ms exceeds timeout 120000 ms\n","22/05/02 22:37:10 WARN SparkContext: Killing executors is not supported by current scheduler.\n"]}],"source":["accuracy=float((true_postives+true_negatives) /(results_positive.count()))\n","print(accuracy)"]}],"metadata":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"},"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
