{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["22/05/02 21:14:40 WARN Utils: Your hostname, herex resolves to a loopback address: 127.0.1.1; using 10.245.4.22 instead (on interface wlp58s0)\n","22/05/02 21:14:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n","WARNING: An illegal reflective access operation has occurred\n","WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/herex/.local/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n","WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n","WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","WARNING: All illegal access operations will be denied in a future release\n","Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n","Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","22/05/02 21:14:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","22/05/02 21:14:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n","22/05/02 21:14:41 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"]}],"source":["import findspark\n","findspark.init()\n","import pyspark\n","sc = pyspark.SparkContext(appName=\"LOGISTICREG\")\n","from pyspark.sql.session import SparkSession\n","spark = SparkSession(sc)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["#read the dataset\n","df=spark.read.csv('data.csv',inferSchema=True,header=True)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- id: integer (nullable = true)\n"," |-- date: string (nullable = true)\n"," |-- news: string (nullable = true)\n"," |-- final_manual_labelling: integer (nullable = true)\n","\n"]}],"source":["df.printSchema()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+---------+--------------------+----------------------+\n","| id|     date|                news|final_manual_labelling|\n","+---+---------+--------------------+----------------------+\n","|  0|1/25/2022|Ripple announces ...|                     1|\n","|  1|1/25/2022|IMF directors urg...|                    -1|\n","|  2|1/25/2022|Dragonfly Capital...|                     1|\n","|  3|1/25/2022|Rick and Morty co...|                     0|\n","|  4|1/25/2022|How fintech SPACs...|                     0|\n","+---+---------+--------------------+----------------------+\n","only showing top 5 rows\n","\n"]}],"source":["df.show(5)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+---------+---------------------------------------------------------------------------------------------------+\n","|id |date     |tokens                                                                                             |\n","+---+---------+---------------------------------------------------------------------------------------------------+\n","|0  |1/25/2022|[ripple, announces, stock, buyback,, nabs, $15, billion, valuation]                                |\n","|1  |1/25/2022|[imf, directors, urge, el, salvador, to, remove, bitcoin, as, legal, tender]                       |\n","|2  |1/25/2022|[dragonfly, capital, is, raising, $500, million, for, new, fund]                                   |\n","|3  |1/25/2022|[rick, and, morty, co-creator, collaborates, with, paradigm, on, nft, research, project]           |\n","|4  |1/25/2022|[how, fintech, spacs, lost, their, shine]                                                          |\n","|5  |1/25/2022|[multichain, vulnerability, put, a, billion, dollars, at, risk,, says, firm, that, found, the, bug]|\n","|6  |1/25/2022|[youtube, wants, to, help, content, creators, capitalize, on, nfts]                                |\n","|7  |1/25/2022|[opensea, is, reimbursing, users, who, sold, nfts, below, market, value, due, to, ui, issue]       |\n","|8  |1/25/2022|[gooddollar, launches, key, protocol, upgrade, to, expand, crypto-backed, ubi, ecosystem]          |\n","|9  |1/25/2022|[bcb, group, raises, a, $60, million, series, a, round, co-led, by, foundation, capital]           |\n","+---+---------+---------------------------------------------------------------------------------------------------+\n","only showing top 10 rows\n","\n"]}],"source":["from pyspark.ml.feature import Tokenizer\n","tokenization=Tokenizer(inputCol='news',outputCol='tokens')\n","tokenized_df=tokenization.transform(df)\n","tokenized_df.select(['id','date','tokens']).show(10,False)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+---------+-------------------------------------------------------------------------------------+\n","|id |date     |refined_tokens                                                                       |\n","+---+---------+-------------------------------------------------------------------------------------+\n","|0  |1/25/2022|[ripple, announces, stock, buyback,, nabs, $15, billion, valuation]                  |\n","|1  |1/25/2022|[imf, directors, urge, el, salvador, remove, bitcoin, legal, tender]                 |\n","|2  |1/25/2022|[dragonfly, capital, raising, $500, million, new, fund]                              |\n","|3  |1/25/2022|[rick, morty, co-creator, collaborates, paradigm, nft, research, project]            |\n","|4  |1/25/2022|[fintech, spacs, lost, shine]                                                        |\n","|5  |1/25/2022|[multichain, vulnerability, put, billion, dollars, risk,, says, firm, found, bug]    |\n","|6  |1/25/2022|[youtube, wants, help, content, creators, capitalize, nfts]                          |\n","|7  |1/25/2022|[opensea, reimbursing, users, sold, nfts, market, value, due, ui, issue]             |\n","|8  |1/25/2022|[gooddollar, launches, key, protocol, upgrade, expand, crypto-backed, ubi, ecosystem]|\n","|9  |1/25/2022|[bcb, group, raises, $60, million, series, round, co-led, foundation, capital]       |\n","+---+---------+-------------------------------------------------------------------------------------+\n","only showing top 10 rows\n","\n"]}],"source":["from pyspark.ml.feature import StopWordsRemover\n","stopword_removal=StopWordsRemover(inputCol='tokens',outputCol='refined_tokens')\n","refined_df=stopword_removal.transform(tokenized_df)\n","refined_df.select(['id','date','refined_tokens']).show(10,False)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+-------------------------------------------------------------------------+------------------------------------------------------------------------------------+\n","|id |refined_tokens                                                           |features                                                                            |\n","+---+-------------------------------------------------------------------------+------------------------------------------------------------------------------------+\n","|0  |[ripple, announces, stock, buyback,, nabs, $15, billion, valuation]      |(6332,[13,30,64,131,398,429,962,5255],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])            |\n","|1  |[imf, directors, urge, el, salvador, remove, bitcoin, legal, tender]     |(6332,[2,122,243,339,612,1205,1309,2930,5019],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n","|2  |[dragonfly, capital, raising, $500, million, new, fund]                  |(6332,[1,3,19,42,470,559,1522],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])                       |\n","|3  |[rick, morty, co-creator, collaborates, paradigm, nft, research, project]|(6332,[4,52,402,421,3624,3821,4271,5010],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])         |\n","+---+-------------------------------------------------------------------------+------------------------------------------------------------------------------------+\n","only showing top 4 rows\n","\n","<class 'pyspark.sql.dataframe.DataFrame'>\n"]}],"source":["# Count Vectorizer\n","from pyspark.ml.feature import CountVectorizer\n","count_vec=CountVectorizer(inputCol='refined_tokens',outputCol='features')\n","cv_df=count_vec.fit(refined_df).transform(refined_df)\n","cv_df.select(['id','refined_tokens','features']).show(4,False)\n","\n","\n","print(type(cv_df))"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------------------+-----+\n","|final_manual_labelling|count|\n","+----------------------+-----+\n","|                    -1|  258|\n","|                     1| 1184|\n","|                     0| 1241|\n","+----------------------+-----+\n","\n"]}],"source":["text_df=cv_df.filter(((cv_df.final_manual_labelling =='1') | (cv_df.final_manual_labelling =='-1')| (cv_df.final_manual_labelling =='0')))\n","text_df.groupBy('final_manual_labelling').count().show()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+----+----------+--------------------+----------------------+--------------------+--------------------+--------------------+-----------+\n","|  id|      date|                news|final_manual_labelling|              tokens|      refined_tokens|            features|token_count|\n","+----+----------+--------------------+----------------------+--------------------+--------------------+--------------------+-----------+\n","|1671| 6/16/2021|DeFi loan platfor...|                     0|[defi, loan, plat...|[defi, loan, plat...|(6332,[6,12,359,4...|          8|\n","|2399| 2/18/2021|BitMEX co-founder...|                     0|[bitmex, co-found...|[bitmex, co-found...|(6332,[64,266,549...|         10|\n","|2191| 3/24/2021|Asset management ...|                     1|[asset, managemen...|[asset, managemen...|(6332,[2,34,69,12...|          7|\n","| 228|12/29/2021|Transient Network...|                     0|[transient, netwo...|[transient, netwo...|(6332,[15,32,33,4...|         10|\n","|1612| 6/24/2021|New York City wil...|                     1|[new, york, city,...|[new, york, city,...|(6332,[2,3,7,153,...|         12|\n","|1379| 7/28/2021|White House says ...|                     0|[white, house, sa...|[white, house, sa...|(6332,[0,7,85,146...|         11|\n","|1203| 8/24/2021|Citigroup is work...|                     1|[citigroup, is, w...|[citigroup, worki...|(6332,[2,11,31,14...|          8|\n","|2396| 2/19/2021|BCB Group launche...|                     1|[bcb, group, laun...|[bcb, group, laun...|(6332,[2,15,81,10...|          9|\n","|1470| 7/15/2021|Blockchain intero...|                     1|[blockchain, inte...|[blockchain, inte...|(6332,[1,5,14,17,...|          9|\n","| 431| 12/4/2021|Solana library bu...|                    -1|[solana, library,...|[solana, library,...|(6332,[1,82,359,1...|          9|\n","+----+----------+--------------------+----------------------+--------------------+--------------------+--------------------+-----------+\n","only showing top 10 rows\n","\n"]},{"data":{"text/plain":["SparseVector(6332, {13: 1.0, 30: 1.0, 64: 1.0, 131: 1.0, 398: 1.0, 429: 1.0, 962: 1.0, 5255: 1.0})"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["from pyspark.sql.functions import udf\n","from pyspark.sql.types import IntegerType\n","from pyspark.sql.functions import *\n","\n","len_udf = udf(lambda s: len(s), IntegerType())\n","\n","refined_text_df = cv_df.withColumn(\"token_count\", len_udf(col('refined_tokens')))\n","refined_text_df.orderBy(rand()).show(10)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["refined_text_df = refined_text_df.withColumn(\"Label\", refined_text_df.final_manual_labelling.cast('float')).drop('final_manual_labelling')"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["['id',\n"," 'date',\n"," 'news',\n"," 'tokens',\n"," 'refined_tokens',\n"," 'features',\n"," 'token_count',\n"," 'Label']"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["refined_text_df.columns"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------------------------------------------------------------------------------------------------+-----------+-----+\n","|features                                                                                                 |token_count|Label|\n","+---------------------------------------------------------------------------------------------------------+-----------+-----+\n","|(6332,[0,195,316,532,831,1090,2323],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                       |7          |1.0  |\n","|(6332,[2,162,296,1224,1454,2396,2462,4669,5375],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                   |9          |0.0  |\n","|(6332,[0,13,305,358,413,1259,2740,3630,4601],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                      |9          |0.0  |\n","|(6332,[0,48,76,92,249,392,596,817,2174,2443,2537],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])         |11         |1.0  |\n","|(6332,[7,11,25,64,101,166,715],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])                                            |7          |-1.0 |\n","|(6332,[10,21,50,98,119,176,231,251,257,285,556],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])           |11         |1.0  |\n","|(6332,[3,51,151,220,222,337,493,521,3224],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                         |9          |1.0  |\n","|(6332,[2,37,1599,1724,1931,4498],[1.0,1.0,1.0,1.0,1.0,1.0])                                              |6          |0.0  |\n","|(6332,[62,156,733,960,1474,1907,1942,5230,5351],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                   |9          |0.0  |\n","|(6332,[0,3,17,126,144,149,291,803,1158,1167,2682,3355],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|12         |1.0  |\n","+---------------------------------------------------------------------------------------------------------+-----------+-----+\n","only showing top 10 rows\n","\n"]}],"source":["refined_text_df.orderBy(rand()).select(['features','token_count','Label']).show(10,False)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+---------+--------------------+--------------------+--------------------+--------------------+-----------+-----+-------------+-------------+\n","| id|     date|                news|              tokens|      refined_tokens|            features|token_count|Label|LabelNegative|LabelPositive|\n","+---+---------+--------------------+--------------------+--------------------+--------------------+-----------+-----+-------------+-------------+\n","|  0|1/25/2022|Ripple announces ...|[ripple, announce...|[ripple, announce...|(6332,[13,30,64,1...|          8|  1.0|          0.0|          1.0|\n","|  1|1/25/2022|IMF directors urg...|[imf, directors, ...|[imf, directors, ...|(6332,[2,122,243,...|          9| -1.0|          1.0|          0.0|\n","|  2|1/25/2022|Dragonfly Capital...|[dragonfly, capit...|[dragonfly, capit...|(6332,[1,3,19,42,...|          7|  1.0|          0.0|          1.0|\n","|  3|1/25/2022|Rick and Morty co...|[rick, and, morty...|[rick, morty, co-...|(6332,[4,52,402,4...|          8|  0.0|          0.0|          0.0|\n","|  4|1/25/2022|How fintech SPACs...|[how, fintech, sp...|[fintech, spacs, ...|(6332,[149,1433,4...|          4|  0.0|          0.0|          0.0|\n","+---+---------+--------------------+--------------------+--------------------+--------------------+-----------+-----+-------------+-------------+\n","only showing top 5 rows\n","\n"]}],"source":["#Tenemos que crear dos modelos ,valor positivo y el resto, y valor negativo y el resto (1,0), y comparar los dos modelos (-1,0)\n","from pyspark.sql.functions import udf\n","from pyspark.sql.types import *\n","\n","funct_negative_label = udf(lambda x: 1.00 if x == -1 else 0.00, FloatType())\n","func_positive_label = udf(lambda x: 1.00 if x == 1 else 0.00, FloatType())\n","\n","refined_text_df = refined_text_df.withColumn(\"LabelNegative\",funct_negative_label('Label'))\n","refined_text_df = refined_text_df.withColumn(\"LabelPositive\",func_positive_label('Label'))\n","\n","refined_text_df.show(5)\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# Veamos si las dos matrices generadas cumplen las caracteristicas que queriamos"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["#Ponemos en el filtro todos los casos 1,0,-1 para ver que las negativas no tenga ningun 1, y las positivas ningun -1\n","text_df_positivo=refined_text_df.filter(((refined_text_df.LabelPositive =='1') | (refined_text_df.LabelPositive =='-1')| (refined_text_df.LabelPositive =='0')))\n","text_df_negativo=refined_text_df.filter(((refined_text_df.LabelNegative =='1') | (refined_text_df.LabelNegative =='-1')| (refined_text_df.LabelNegative =='0')))\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------------+-----+\n","|LabelNegative|count|\n","+-------------+-----+\n","|          1.0|  258|\n","|          0.0| 2425|\n","+-------------+-----+\n","\n"]}],"source":["text_df_negativo.groupBy('LabelNegative').count().show()"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------------+-----+\n","|LabelPositive|count|\n","+-------------+-----+\n","|          1.0| 1184|\n","|          0.0| 1499|\n","+-------------+-----+\n","\n"]}],"source":["text_df_positivo.groupBy('LabelPositive').count().show()"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["from pyspark.ml.feature import VectorAssembler\n","\n","df_assembler = VectorAssembler(inputCols=['features','token_count'],outputCol='features_vec')\n","model_text_df = df_assembler.transform(refined_text_df)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+\n","|        features_vec|\n","+--------------------+\n","|(6333,[13,30,64,1...|\n","+--------------------+\n","only showing top 1 row\n","\n"]}],"source":["model_text_df.select(['features_vec']).show(1)\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["from pyspark.ml.classification import LogisticRegression,LogisticRegressionModel\n","#split the data \n","training_df_negative,test_df_negative=model_text_df.randomSplit([0.75,0.25])\n","#split the data \n","training_df_positive,test_df_positive=model_text_df.randomSplit([0.75,0.25])"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["22/05/02 21:14:54 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n","22/05/02 21:14:54 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"]}],"source":["log_reg_positive = LogisticRegression(featuresCol='features_vec',labelCol='LabelPositive').fit(training_df_positive)\n","log_reg_negative = LogisticRegression(featuresCol='features_vec',labelCol='LabelNegative').fit(training_df_negative)\n","\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# log_reg_negative.write().save(\"./model_neg\")\n","# log_reg_positive.write().save(\"./model_pos\")\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["model_neg = LogisticRegressionModel.load(\"model_neg\")\n","model_pos = LogisticRegressionModel.load(\"model_pos\")"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- data: string (nullable = true)\n","\n","+-----------------------------------------------------------------------------------------------------+\n","|tokens                                                                                               |\n","+-----------------------------------------------------------------------------------------------------+\n","|[visa, announces, crypto, partnership, with, neobank, focused, on, services, for, black, communities]|\n","+-----------------------------------------------------------------------------------------------------+\n","\n","+--------------------------------------------------------------------------------------+\n","|refined_tokens                                                                        |\n","+--------------------------------------------------------------------------------------+\n","|[visa, announces, crypto, partnership, neobank, focused, services, black, communities]|\n","+--------------------------------------------------------------------------------------+\n","\n","+--------------------+--------------------+\n","|            features|      refined_tokens|\n","+--------------------+--------------------+\n","|(9,[0,1,2,3,4,5,6...|[visa, announces,...|\n","+--------------------+--------------------+\n","\n"]},{"ename":"TypeError","evalue":"int() argument must be a string, a bytes-like object or a number, not 'DenseVector'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_135737/3532289641.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_assembler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefined_text_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mpepe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mpepe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/linalg/__init__.py\u001b[0m in \u001b[0;36msparse\u001b[0;34m(size, *args)\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0mSparseVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m5.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m         \"\"\"\n\u001b[0;32m--> 795\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSparseVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/linalg/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, size, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mAssertionError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mContains\u001b[0m \u001b[0mnegative\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \"\"\"\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0;34m\"\"\" Size of the vector. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"must pass either 2 or 3 arguments\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'DenseVector'"]}],"source":["from pyspark.ml.linalg import Vectors\n","df = spark.createDataFrame([\n","    (1.0, Vectors.dense(1.0)),\n","    (0.0, Vectors.sparse(1, [], []))], [\"label\", \"features\"])\n","\n","df = spark.createDataFrame([('Visa announces crypto partnership with neobank focused on services for Black communities',)], [\"data\"])\n","\n","df.printSchema()\n","\n","tokenization=Tokenizer(inputCol='data',outputCol='tokens')\n","tokenized_df=tokenization.transform(df)\n","tokenized_df.select(['tokens']).show(10,False)\n","\n","stopword_removal=StopWordsRemover(inputCol='tokens',outputCol='refined_tokens')\n","refined_df=stopword_removal.transform(tokenized_df)\n","refined_df.select(['refined_tokens']).show(10,False)\n","\n","count_vec=CountVectorizer(inputCol='refined_tokens',outputCol='features')\n","cv_df=count_vec.fit(refined_df).transform(refined_df)\n","\n","\n","len_udf = udf(lambda s: len(s), IntegerType())\n","\n","refined_text_df = cv_df.withColumn(\"token_count\", len_udf(col('refined_tokens')))\n","\n","refined_text_df.select(['features','refined_tokens']).show(2)\n","\n","\n","df_assembler = VectorAssembler(inputCols=['features','token_count'],outputCol='features_vec')\n","df = df_assembler.transform(refined_text_df)\n","\n","pepe = Vectors.sparse(df.head().features_vec)\n","pepe\n"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"ename":"IllegalArgumentException","evalue":"requirement failed: BLAS.dot(x: Vector, y:Vector) was given Vectors with non-matching sizes: x.size = 9, y.size = 6333","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_135737/3440078297.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_neg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mPredict\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \"\"\"\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_call_java\u001b[0;34m(self, name, *args)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mjava_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjava_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: BLAS.dot(x: Vector, y:Vector) was given Vectors with non-matching sizes: x.size = 9, y.size = 6333"]}],"source":["model_neg.predict(df.head().features)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/herex/.local/lib/python3.8/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n","  warnings.warn(\n"]}],"source":["results_positive = log_reg_positive.evaluate(test_df_positive).predictions\n","results_negative = log_reg_negative.evaluate(test_df_negative).predictions"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+---------+--------------------+--------------------+--------------------+--------------------+-----------+-----+-------------+-------------+--------------------+--------------------+--------------------+----------+\n","| id|     date|                news|              tokens|      refined_tokens|            features|token_count|Label|LabelNegative|LabelPositive|        features_vec|       rawPrediction|         probability|prediction|\n","+---+---------+--------------------+--------------------+--------------------+--------------------+-----------+-----+-------------+-------------+--------------------+--------------------+--------------------+----------+\n","| 11|1/25/2022|Twitter is growin...|[twitter, is, gro...|[twitter, growing...|(6332,[0,125,232,...|          5|  1.0|          0.0|          1.0|(6333,[0,125,232,...|[0.13665244936135...|[0.53411004824051...|       0.0|\n","| 13|1/24/2022|Walmart director ...|[walmart, directo...|[walmart, directo...|(6332,[0,76,96,11...|          8|  1.0|          0.0|          1.0|(6333,[0,76,96,11...|[-31.033289694625...|[3.32976458830554...|       1.0|\n","| 16|1/24/2022|Ribbon Finance: a...|[ribbon, finance:...|[ribbon, finance:...|(6332,[276,348,20...|          6|  0.0|          0.0|          0.0|(6333,[276,348,20...|[3.67006743024184...|[0.97515808939478...|       0.0|\n","| 17|1/24/2022|OKO Miners Announ...|[oko, miners, ann...|[oko, miners, ann...|(6332,[9,30,40,43...|          8|  0.0|          0.0|          0.0|(6333,[9,30,40,43...|[5.71239985484533...|[0.99670615313824...|       0.0|\n","| 18|1/24/2022|MetaVisa will sta...|[metavisa, will, ...|[metavisa, start,...|(6332,[28,63,330,...|          7|  0.0|          0.0|          0.0|(6333,[28,63,330,...|[14.1401723536730...|[0.99999927722876...|       0.0|\n","+---+---------+--------------------+--------------------+--------------------+--------------------+-----------+-----+-------------+-------------+--------------------+--------------------+--------------------+----------+\n","only showing top 5 rows\n","\n"]}],"source":["results_positive.show(5)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["#confusion matrix positive model\n","true_postives = results_positive[(results_positive.Label == 1) & (results_positive.prediction == 1)].count()\n","true_negatives = results_positive[(results_positive.Label == 0) & (results_positive.prediction == 0)].count()\n","false_positives = results_positive[(results_positive.Label == 0) & (results_positive.prediction == 1)].count()\n","false_negatives = results_positive[(results_positive.Label == 1) & (results_positive.prediction == 0)].count()"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.6655052264808362\n"]}],"source":["recall = float(true_postives)/(true_postives + false_negatives)\n","print(recall)"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.6797153024911032\n"]}],"source":["precision = float(true_postives) / (true_postives + false_positives)\n","print(precision)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.6130952380952381\n"]}],"source":["accuracy=float((true_postives+true_negatives) /(results_positive.count()))\n","print(accuracy)"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["#confusion matrix negative model\n","true_postives = results_negative[(results_negative.Label == 1) & (results_negative.prediction == 1)].count()\n","true_negatives = results_negative[(results_negative.Label == 0) & (results_negative.prediction == 0)].count()\n","false_positives = results_negative[(results_negative.Label == 0) & (results_negative.prediction == 1)].count()\n","false_negatives = results_negative[(results_negative.Label == 1) & (results_negative.prediction == 0)].count()"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.02158273381294964\n"]}],"source":["recall = float(true_postives)/(true_postives + false_negatives)\n","print(recall)"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.21428571428571427\n"]}],"source":["precision = float(true_postives) / (true_postives + false_positives)\n","print(precision)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.45535714285714285\n"]}],"source":["accuracy=float((true_postives+true_negatives) /(results_positive.count()))\n","print(accuracy)"]}],"metadata":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"},"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
